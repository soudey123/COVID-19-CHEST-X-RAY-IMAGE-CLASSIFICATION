{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG16-Covid19-Classification-V2.0.ipynb","private_outputs":true,"provenance":[{"file_id":"1SfIAQR0ZhepL8zCpMzk80cizfflLqfFl","timestamp":1618251907697}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"epGd8bfZQO1l"},"source":["\n","\n","\n","### **COVID-19 Classification using pretrained VGG16 architecture**"]},{"cell_type":"markdown","metadata":{"id":"Q-Bt-MXrwWKT"},"source":["**1. Mount google drive to download the images**"]},{"cell_type":"code","metadata":{"id":"bQMJ3R2PvEou"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tqLITJ1owjTm"},"source":["**2. Importing required modules and libraries**"]},{"cell_type":"code","metadata":{"id":"vLgNmD86woYH"},"source":["from __future__ import print_function, division\n","\n","import os\n","import zipfile\n","import random\n","import numpy as np\n","import time\n","import copy\n","import shutil\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.autograd import Variable\n","\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nh5U4rMUw-RM"},"source":["**3. Using CUDA**"]},{"cell_type":"code","metadata":{"id":"fdOErGkyxTic"},"source":["use_gpu = torch.cuda.is_available()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_dU6Lj-sxWTR"},"source":["**4. Download and Unzip the data file**"]},{"cell_type":"code","metadata":{"id":"TpUQpzcUt4i7"},"source":["drive_dir='/content/drive/MyDrive/DS-Data/'\n","zip_filename = 'Data.zip'\n","\n","src_root_dir='Combined-Data'\n","trg_root_dir='Splitted-Data'\n","classes_dir = ['PNEUMONIA', 'NORMAL', 'COVID19']\n","\n","DATA_PATH = trg_root_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yOhMJSUNdlut"},"source":["def data_download_unzip():\n","  local_zip = drive_dir + '/' + zip_filename\n","  zip_ref = zipfile.ZipFile(local_zip, 'r')\n","  zip_ref.extractall('/content')\n","  zip_ref.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gkt0E78luEDG"},"source":["data_download_unzip()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wrHhusbZtchU"},"source":["**4.a Split data into train, test and validation**"]},{"cell_type":"code","metadata":{"id":"b271H1TDs-SH"},"source":["def train_val_test_split(val_ratio=0.15, test_ratio=0.15):\n","  \n","  !rm -rf Splitted-Data\n","\n","  if not os.path.exists(trg_root_dir):\n","      os.makedirs(trg_root_dir)\n"," \n","  for cls in classes_dir:\n","    if not os.path.exists(trg_root_dir +'/train/' + cls):\n","      os.makedirs(trg_root_dir +'/train/' + cls)\n","    if not os.path.exists(trg_root_dir +'/val/' + cls):\n","      os.makedirs(trg_root_dir +'/val/' + cls)\n","    if not os.path.exists(trg_root_dir +'/test/' + cls):\n","      os.makedirs(trg_root_dir +'/test/' + cls)\n","\n","    # Creating partitions of the data after shuffeling\n","    src = src_root_dir + '/' + cls # Folder to copy images from\n","    allFileNames = os.listdir(src)\n","  \n","    np.random.shuffle(allFileNames)\n","    train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n","                                                              [int(len(allFileNames)* (1 - val_ratio - test_ratio)), \n","                                                               int(len(allFileNames)* (1 - test_ratio))])\n","\n","    train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n","    val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\n","    test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n","    print('Splitting data for the class : ', cls)\n","    print('Total images: ', len(allFileNames))\n","    print('Training: ', len(train_FileNames))\n","    print('Validation: ', len(val_FileNames))\n","    print('Testing: ', len(test_FileNames))\n","\n","    # Copy-pasting images\n","\n","    for name in train_FileNames:\n","        shutil.copy(name, trg_root_dir +'/train/' + cls)\n","\n","    for name in val_FileNames:\n","        shutil.copy(name, trg_root_dir +'/val/' + cls)\n","\n","    for name in test_FileNames:\n","        shutil.copy(name, trg_root_dir +'/test/' + cls)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"omQw2_JTuHJQ"},"source":["train_val_test_split(0.15, 0.15)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"APPiNun0QqIv"},"source":["**5. Data augmentation and statistics**"]},{"cell_type":"code","metadata":{"id":"dWSAGy5SxxiB"},"source":["TRAIN = 'train'\n","VAL = 'val'\n","TEST = 'test'\n","\n","data_transforms = {\n","  TRAIN: transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","  ]),\n","\n","  VAL: transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","  ]),\n","\n","  TEST: transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","  ])\n","}\n","\n","image_datasets = {\n","  x: datasets.ImageFolder(\n","      os.path.join(DATA_PATH, x), \n","      transform=data_transforms[x]\n","  )\n","  for x in [TRAIN, VAL, TEST]\n","}\n","\n","dataloaders = {\n","  x: torch.utils.data.DataLoader(\n","      image_datasets[x], batch_size=8,\n","      shuffle=True, num_workers=4\n","  )\n","  for x in [TRAIN, VAL, TEST]\n","}\n","  \n","dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\n","\n","for x in [TRAIN, VAL, TEST]:\n","  print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n","\n","\n","class_names = image_datasets[TRAIN].classes\n","print(\"Classes: \", image_datasets[TRAIN].classes)\n","\n","def get_count_metrics(folder, data_path=DATA_PATH):\n","\n","    train_dir = os.path.join(data_path, folder)\n","    list_p = os.listdir(os.path.join(train_dir,'PNEUMONIA')) # dir is your directory path\n","    num_p = len(list_p)\n","    list_n = os.listdir(os.path.join(train_dir,'NORMAL')) # dir is your directory path\n","    num_n = len(list_n)\n","    list_c = os.listdir(os.path.join(train_dir,'COVID19')) # dir is your directory path\n","    num_c = len(list_c)\n","    count_tuple = (int(num_n), int(num_p), int(num_c))\n","\n","    return count_tuple\n","\n","print(get_count_metrics('train'))\n","print(get_count_metrics('test'))\n","print(get_count_metrics('val'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oAcobmr8Q6Za"},"source":["**6. Visualize the dataset/images**"]},{"cell_type":"code","metadata":{"id":"yT8aSK9H3uSs"},"source":["def imshow(inp, title=None):\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    plt.axis('off')\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)\n","\n","def show_databatch(inputs, classes):\n","    out = torchvision.utils.make_grid(inputs)\n","    imshow(out, title=[class_names[x] for x in classes])\n","\n","# Get a batch of training data\n","inputs, classes = next(iter(dataloaders[TRAIN]))\n","show_databatch(inputs, classes)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-LIEXWdm2fLA"},"source":["**7. Define the VGG16 model**\n","  \n","\n","*   Setting the model pre-trained parameter to True\n","*   Customizing the last fully connected layer with 3 output classes\n","*   Setting requires_grad to false for all layers \n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ShK23VJ8F4h6"},"source":["vgg16 = models.vgg16_bn(pretrained=True)\n","\n","# Freeze training for all layers\n","for param in vgg16.features.parameters():\n","    param.require_grad = False\n","\n","num_features = vgg16.classifier[6].in_features\n","features = list(vgg16.classifier.children())[:-1] # Remove last layer\n","features.extend([nn.Linear(num_features, len(class_names))]) # Add our layer with 4 outputs\n","vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n","\n","if use_gpu: \n","  vgg16.cuda()\n","\n","print(vgg16)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tf9RZ2dZxW13"},"source":["**7. Define loss function and optimizer**"]},{"cell_type":"code","metadata":{"id":"Wq4dqdTxxckO"},"source":["criterion = nn.CrossEntropyLoss()\n","\n","optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wnMYfBbWs5u-"},"source":["**8. Define funtion to evaluate test dataset and calculate accuracy**"]},{"cell_type":"code","metadata":{"id":"pb8R9zkVtCox"},"source":["def eval_model(vgg, criterion):\n","    since = time.time()\n","    avg_loss = 0\n","    avg_acc = 0\n","    loss_test = 0\n","    acc_test = 0\n","    \n","    test_batches = len(dataloaders[TEST])\n","    print(\"Evaluating model. Total test batchs - \", test_batches)\n","    print('-' * 30)\n","    \n","\n","    for i, data in enumerate(dataloaders[TEST]):\n","        if i % 100 == 0:\n","            print(\"\\rTest batch {}/{} is in progress\\n\".format(i+1, test_batches), end='', flush=True)\n","\n","        vgg.train(False)\n","        vgg.eval()\n","\n","        inputs, labels = data\n","        if use_gpu:\n","            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n","        else:\n","            inputs, labels = Variable(inputs), Variable(labels)\n","\n","        outputs = vgg(inputs)\n","        _, preds = torch.max(outputs.data, 1)\n","        loss = criterion(outputs, labels)\n","\n","        loss_test += loss.item()\n","        acc_test += torch.sum(preds == labels.data)\n","        del inputs, labels, outputs, preds\n","        torch.cuda.empty_cache()\n","        \n","    avg_loss = loss_test / dataset_sizes[TEST]\n","    avg_acc = acc_test / dataset_sizes[TEST]\n","    \n","    elapsed_time = time.time() - since\n","    print()\n","    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n","    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n","    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n","    print('-' * 10)\n","    return avg_loss, avg_acc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8dOVWnR5YWy"},"source":["**9. Test the model accuracy before training**"]},{"cell_type":"code","metadata":{"id":"L9Ji2dcN6zv2"},"source":["#eval_model(vgg16, criterion)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P76mP3q_51rX"},"source":["**10. Define funtion to train the model with train data**"]},{"cell_type":"code","metadata":{"id":"O7viVI6H3Dv3"},"source":["def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n","\n","    since = time.time()\n","    best_model_wts = copy.deepcopy(vgg.state_dict())\n","    \n","    best_acc = avg_loss = avg_acc = avg_loss_val = avg_acc_val = 0.0\n","   \n","    train_batches = len(dataloaders[TRAIN])\n","    val_batches = len(dataloaders[VAL])\n","    \n","    for epoch in range(num_epochs):\n","        print(\"Epoch {}/{} is in progress\".format(epoch+1, num_epochs))\n","        print('-' * 30)\n","        \n","        loss_train = loss_val = acc_train = acc_val = 0.0\n","\n","        vgg.train(True)\n","\n","        for i, data in enumerate(dataloaders[TRAIN]):\n","            if i % 100 == 0:\n","                print(\"\\rTraining batch {}/{} is in progress\\n\".format(i+1, train_batches), end='', flush=True)\n","                \n","            #Use half training dataset\n","            #if i >= train_batches / 2:\n","            #   break\n","                \n","            inputs, labels = data\n","            if use_gpu:\n","                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n","            else:\n","                inputs, labels = Variable(inputs), Variable(labels)\n","            \n","            optimizer.zero_grad()\n","            outputs = vgg(inputs)\n","            \n","            _, preds = torch.max(outputs.data, 1)\n","            loss = criterion(outputs, labels)            \n","            loss.backward()\n","            optimizer.step()            \n","        \n","            loss_train += loss.item()\n","            acc_train += torch.sum(preds == labels.data)           \n","            del inputs, labels, outputs, preds\n","            torch.cuda.empty_cache()\n","        \n","        avg_loss = loss_train/dataset_sizes[TRAIN]\n","        avg_acc = acc_train/dataset_sizes[TRAIN]\n","              \n","        vgg.train(False)\n","        vgg.eval()\n","            \n","        for i, data in enumerate(dataloaders[VAL]):\n","            if i % 100 == 0:\n","                print(\"\\rValidation batch {}/{} is in progress\\n\".format(i+1, val_batches), end='', flush=True)\n","                \n","            inputs, labels = data            \n","            if use_gpu:\n","                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n","            else:\n","                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n","            \n","            optimizer.zero_grad()            \n","            outputs = vgg(inputs)\n","\n","            _, preds = torch.max(outputs.data, 1)\n","            loss = criterion(outputs, labels)\n","\n","            loss_val += loss.item()\n","            acc_val += torch.sum(preds == labels.data)            \n","            del inputs, labels, outputs, preds\n","            torch.cuda.empty_cache()\n","        \n","        avg_loss_val = loss_val/dataset_sizes[VAL]\n","        avg_acc_val = acc_val/dataset_sizes[VAL]\n","        \n","        print()\n","        print(\"Epoch {} result: \".format(epoch))\n","        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n","        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n","        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n","        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n","        print('-' * 30)\n","        print()\n","\n","        if avg_acc_val > best_acc:\n","            best_acc = avg_acc_val\n","            best_model_wts = copy.deepcopy(vgg.state_dict())\n","        \n","    elapsed_time = time.time() - since\n","    print()\n","    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n","    print(\"Best acc: {:.4f}\".format(best_acc))\n","    \n","    vgg.load_state_dict(best_model_wts)\n","    return vgg, avg_loss_val, avg_acc_val\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BQ-_ISZeFpq2"},"source":["**11. Define funtion to predict classification for few images**"]},{"cell_type":"code","metadata":{"id":"UUsv5nz-CX2a"},"source":["def visualize_model(vgg, num_images=6):\n","    was_training = vgg.training\n","    \n","    # Set model for evaluation\n","    vgg.train(False)\n","    vgg.eval() \n","    \n","    images_so_far = 0\n","\n","    for i, data in enumerate(dataloaders[TEST]):\n","        inputs, labels = data\n","        size = inputs.size()[0]\n","        \n","        if use_gpu:\n","            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n","        else:\n","            inputs, labels = Variable(inputs), Variable(labels)\n","        \n","        outputs = vgg(inputs)\n","\n","        _, preds = torch.max(outputs.data, 1)\n","        predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n","        \n","        print(\"Ground truth:\")\n","        show_databatch(inputs.data.cpu(), labels.data.cpu())\n","        print(\"Prediction:\")\n","        show_databatch(inputs.data.cpu(), predicted_labels)\n","        \n","        del inputs, labels, outputs, preds, predicted_labels\n","        torch.cuda.empty_cache()\n","        \n","        images_so_far += size\n","        if images_so_far >= num_images:\n","            break\n","        \n","    vgg.train(mode=was_training) # Revert model back to original training state"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"deD-Tsu_7GGD"},"source":["**12. Train the model on train dataset**"]},{"cell_type":"code","metadata":{"id":"KTC1-ZHA3Uxr"},"source":["vgg16, avg_loss_val, avg_acc_val = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tf-AprW97eTI"},"source":["**13. Evaluae the model on test dataset**"]},{"cell_type":"code","metadata":{"id":"UyKHuYS-3cL6"},"source":["avg_loss_test, avg_acc_test = eval_model(vgg16, criterion)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bCPxbbXw7pYl"},"source":["**14. Plot accuracy and loss**"]},{"cell_type":"code","metadata":{"id":"pJYMNnMjvtzy"},"source":["#plt.figure(figsize=(10, 7))\n","#plt.plot(train_accuracy, color='green', label='train accuracy')\n","#plt.plot(val_accuracy, color='blue', label='validataion accuracy')\n","#plt.legend()\n","#plt.savefig('accuracy.png')\n","#plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5pgWzAEK724L"},"source":["**15. Predict classification for few images**"]},{"cell_type":"code","metadata":{"id":"XFGtBqLJ3glo"},"source":["visualize_model(vgg16, num_images=32)"],"execution_count":null,"outputs":[]}]}